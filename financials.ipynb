{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "from edgar import *\n",
    "from tqdm import tqdm\n",
    "from urllib3 import Retry\n",
    "from edgar.xbrl import XBRLS\n",
    "from datetime import datetime\n",
    "from requests.adapters import HTTPAdapter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger(\"openai\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "request = requests.Session()\n",
    "retries = Retry(\n",
    "    total=3,  # 最多重試 5 次\n",
    "    backoff_factor=1,  # 每次重試的延遲時間指數增長（1s, 2s, 4s, 8s...）\n",
    "    status_forcelist=[403, 429, 500, 502, 503, 504],  # 針對這些 HTTP 狀態碼進行重試\n",
    ")\n",
    "request.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "request.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "headers = {\"User-Agent\": \"ansa ansa1019@gmail.com\"}\n",
    "\n",
    "\n",
    "# 公司名單\n",
    "companies_range = 100\n",
    "df_companies = pd.read_csv(\"sp500_companies.csv\")\n",
    "companies = df_companies.drop_duplicates(subset=[\"Shortname\"], keep=\"first\")[\n",
    "    \"Symbol\"\n",
    "].values[:companies_range]\n",
    "with open(\"companies.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "missing_companies = [entry[\"ticker\"] for entry in data[\"missing_companies\"]]\n",
    "find_cik = {entry[\"ticker\"]: entry[\"cik\"] for entry in data[\"find_cik\"]}\n",
    "companies = [c for c in companies if c not in missing_companies]\n",
    "\n",
    "# 參數設定\n",
    "set_identity(\"ansa ansa1019@gmail.com\")\n",
    "search_queries = [\"IT capability\", \"organizational resilience\"]\n",
    "keywords = {q: [q] for q in search_queries}\n",
    "report_item = {\"paper_7\": [\"7\"], \"paper_17\": [\"1A\", \"7\"]}\n",
    "report_papers = \"papers.json\"\n",
    "financials_file = \"financials.csv\"\n",
    "report_year = [2014, 2023]\n",
    "minlen = 1500\n",
    "keyword_num = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def\n",
    "def extract_financials(cik, year, extract_type=None):\n",
    "    company = Company(cik)\n",
    "    df = company.get_facts().to_pandas()\n",
    "    df = df[(df[\"form\"] == \"10-K\") & (df[\"namespace\"] == \"us-gaap\")]\n",
    "    filings = company.get_filings(form=[\"10-K\"], date=f\"{year}-01-01:{year+1}-12-31\")\n",
    "    if not filings:\n",
    "        return None\n",
    "\n",
    "    # 選取符合該年度報告的 filing\n",
    "    filing = None\n",
    "    for f in filings:\n",
    "        report_date = datetime.fromisoformat(f.report_date)\n",
    "        report_year = (\n",
    "            report_date.year - 1 if report_date.month <= 3 else report_date.year\n",
    "        )\n",
    "        if report_year == year:\n",
    "            filing = f\n",
    "            break\n",
    "    if not filing:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        income = (\n",
    "            XBRLS.from_filings(filings).statements.income_statement().to_dataframe()\n",
    "        )\n",
    "    except:\n",
    "        income = pd.DataFrame()\n",
    "\n",
    "    url = f\"https://www.sec.gov/Archives/edgar/data/{filing.cik}/{filing.accession_no.replace('-', '')}/{filing.primary_document}\"\n",
    "\n",
    "    facts = {\n",
    "        \"Revenues\": {\n",
    "            # 高優先：標準與 ASC 606 定義\n",
    "            \"High\": [\n",
    "                \"Revenues\",\n",
    "                \"RevenueFromContractWithCustomerExcludingAssessedTax\",\n",
    "                \"RevenueFromContractWithCustomerIncludingAssessedTax\",\n",
    "            ],\n",
    "            # 中優先：銷售細分類（商品、服務）\n",
    "            \"Medium\": [\n",
    "                \"SalesRevenueNet\",\n",
    "                \"SalesRevenueGoodsNet\",\n",
    "                \"SalesRevenueServicesNet\",\n",
    "            ],\n",
    "            # 特定產業\n",
    "            \"Low\": [\n",
    "                \"RevenuesNetOfInterestExpense\",\n",
    "                \"RealEstateRevenueNet\",\n",
    "                \"RegulatedAndUnregulatedOperatingRevenue\",\n",
    "            ],\n",
    "            # 最後備援：模擬資料\n",
    "            # \"BusinessAcquisitionsProFormaRevenue\",\n",
    "        },\n",
    "        \"Income\": {\n",
    "            # 高優先：標準最終淨利\n",
    "            \"High\": [\"NetIncomeLoss\", \"ProfitLoss\"]\n",
    "            # 中優先：普通股基本淨利\n",
    "            # \"NetIncomeLossAvailableToCommonStockholdersBasic\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def safe_extract(target):\n",
    "        def parse_val(val):\n",
    "            return float(re.sub(\"[—−]\", \"-\", re.sub(r\"[\\s,]+\", \"\", str(val))))\n",
    "\n",
    "        if target == \"Revenues\":\n",
    "            levels = [\"High\", \"Medium\", \"Low\"]\n",
    "        else:\n",
    "            levels = [None]  # 單層清單\n",
    "\n",
    "        for level in levels:\n",
    "            total = 0\n",
    "            found = []\n",
    "            fact_list = facts[target][level] if level else facts[target]\n",
    "\n",
    "            # Income statement\n",
    "            for fact in fact_list:\n",
    "                if not income.empty and fact in income.columns:\n",
    "                    row = income[income[\"concept\"] == fact]\n",
    "                    for col in income.columns[2:]:\n",
    "                        col_date = datetime.fromisoformat(col)\n",
    "                        report_year = (\n",
    "                            col_date.year if col_date.month > 3 else col_date.year - 1\n",
    "                        )\n",
    "                        if report_year == year:\n",
    "                            val = row[col].values[0]\n",
    "                            if pd.notna(val):\n",
    "                                total += float(val)\n",
    "                                found.append(fact)\n",
    "                            break\n",
    "            if found:\n",
    "                return (total if len(found) > 1 else float(total)), \"+\".join(found)\n",
    "\n",
    "            # df[\"frame\"]\n",
    "            for fact in fact_list:\n",
    "                col = df[(df[\"fact\"] == fact) & (df[\"frame\"] == f\"CY{year}\")]\n",
    "                if not col.empty:\n",
    "                    val = col.sort_values(\"filed\", ascending=False)[\"val\"].iloc[0]\n",
    "                    if val:\n",
    "                        total += parse_val(val)\n",
    "                        found.append(fact)\n",
    "            if found:\n",
    "                return (total if len(found) > 1 else float(total)), \"+\".join(found)\n",
    "\n",
    "            # df[\"end\"]\n",
    "            for fact in fact_list:\n",
    "                col = df[(df[\"fact\"] == fact) & (df[\"end\"].str.startswith(str(year)))]\n",
    "                if not col.empty:\n",
    "                    val = col.sort_values(\"filed\", ascending=False)[\"val\"].iloc[0]\n",
    "                    if val:\n",
    "                        total += parse_val(val)\n",
    "                        found.append(fact)\n",
    "            if found:\n",
    "                return (total if len(found) > 1 else float(total)), \"+\".join(found)\n",
    "\n",
    "            # Inline XBRL\n",
    "            try:\n",
    "                response = requests.get(\n",
    "                    url, headers={\"User-Agent\": \"ansa1019@gmail.com\"}\n",
    "                )\n",
    "                soup = BeautifulSoup(response.content, \"lxml\")\n",
    "                for fact in fact_list:\n",
    "                    for tag in soup.find_all(\n",
    "                        \"ix:nonfraction\", {\"name\": f\"us-gaap:{fact}\"}\n",
    "                    ):\n",
    "                        contextref = tag.get(\"contextref\")\n",
    "                        context = soup.find(id=contextref)\n",
    "                        end_tag = context.find(\"xbrli:enddate\")\n",
    "                        report_date = datetime.fromisoformat(end_tag.text.strip())\n",
    "                        report_year = (\n",
    "                            report_date.year - 1\n",
    "                            if report_date.month <= 3\n",
    "                            else report_date.year\n",
    "                        )\n",
    "                        if report_year == year and context.find(\"xbrli:segment\"):\n",
    "                            val = tag.text\n",
    "                            if val:\n",
    "                                total += parse_val(val)\n",
    "                                found.append(fact)\n",
    "                if found:\n",
    "                    return (total if len(found) > 1 else float(total)), \"+\".join(found)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Inline XBRL 抓取失敗：{e}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    fact_list = []\n",
    "    revenues = income_val = None\n",
    "\n",
    "    result = safe_extract(\"Revenues\")\n",
    "    if result:\n",
    "        fact_list.append(result)\n",
    "\n",
    "    result = safe_extract(\"Income\")\n",
    "    if result:\n",
    "        fact_list.append(result)\n",
    "\n",
    "    return fact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在抓取 LRCX 2014 年的財務資料...: 100%|██████████| 70/70 [14:00<00:00, 12.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 財務資料已保存到: financials.csv\n",
      "⚠️ 錯誤紀錄：\n",
      "❌ 無法取得 AAPL 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 MSFT 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 AMZN 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 MA 2015 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ORCL 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 PG 2015 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 HD 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ABBV 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 KO 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 MRK 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 PEP 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 TMO 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ABT 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 AMD 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 PM 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ISRG 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 INTU 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 GS 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 TXN 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 BKNG 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 DHR 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 NEE 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ANET 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 LOW 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 SYK 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 UNP 2015 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 KKR 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 SCHW 2014 年的數據: 'NoneType' object has no attribute 'columns'\n",
      "❌ 無法取得 AMAT 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 BMY 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 LMT 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 GILD 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 NKE 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 ADI 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 MMC 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 MU 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 SBUX 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 PLD 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "❌ 無法取得 LRCX 2014 年的數據: cannot unpack non-iterable NoneType object\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 財務資料\n",
    "log = \"\"\n",
    "financial_data = {}\n",
    "loop = tqdm(companies)\n",
    "for ticker in loop:\n",
    "    searchs = [ticker] + find_cik[ticker] if ticker in find_cik else [ticker]\n",
    "    for search in searchs:\n",
    "        try:\n",
    "            for year in range(report_year[0], report_year[1] + 1):\n",
    "                loop.set_description(f\"正在抓取 {ticker} {year} 年的財務資料...\")\n",
    "                financial_data.setdefault(ticker, {}).setdefault(\n",
    "                    year, {\"Revenues\": None, \"Net Income\": None}\n",
    "                )\n",
    "                if (\n",
    "                    financial_data[ticker][year][\"Revenues\"] is not None\n",
    "                    and financial_data[ticker][year][\"Net Income\"] is not None\n",
    "                ):\n",
    "                    continue\n",
    "                result = extract_financials(search, year)\n",
    "                if result is not None:\n",
    "                    revenues, income = result\n",
    "                    if revenues is not None:\n",
    "                        financial_data[ticker][year][\"Revenues\"] = revenues\n",
    "                    if income is not None:\n",
    "                        financial_data[ticker][year][\"Net Income\"] = income\n",
    "        except Exception as e:\n",
    "            log += f\"❌ 無法取得 {ticker} {year} 年的數據: {e}\\n\"\n",
    "\n",
    "# 轉為 DataFrame 並輸出\n",
    "flat_data = []\n",
    "for ticker, years in financial_data.items():\n",
    "    for year, values in years.items():\n",
    "        row = {\n",
    "            \"ticker\": ticker,\n",
    "            \"year\": year,\n",
    "            \"Revenues\": values.get(\"Revenues\"),\n",
    "            \"Net Income\": values.get(\"Net Income\"),\n",
    "        }\n",
    "        flat_data.append(row)\n",
    "df = pd.DataFrame(flat_data)\n",
    "df.to_csv(financials_file, index=False)\n",
    "print(f\"📁 財務資料已保存到: {financials_file}\")\n",
    "\n",
    "if log:\n",
    "    print(\"⚠️ 錯誤紀錄：\\n\" + log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>year</th>\n",
       "      <th>Revenues</th>\n",
       "      <th>Net Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>MA</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PG</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HD</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>KO</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>MRK</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>TMO</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>ABT</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>PM</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ISRG</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>INTU</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>GS</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>TXN</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>BKNG</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>DHR</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NEE</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ANET</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>LOW</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>SYK</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>UNP</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>KKR</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>SCHW</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>AMAT</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>BMY</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>LMT</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>GILD</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>NKE</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>ADI</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>MMC</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>MU</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>SBUX</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>PLD</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker  year  Revenues  Net Income\n",
       "0     AAPL  2014       NaN         NaN\n",
       "11    MSFT  2014       NaN         NaN\n",
       "12    AMZN  2014       NaN         NaN\n",
       "74      MA  2015       NaN         NaN\n",
       "75    ORCL  2014       NaN         NaN\n",
       "97      PG  2015       NaN         NaN\n",
       "98      HD  2014       NaN         NaN\n",
       "129   ABBV  2014       NaN         NaN\n",
       "130     KO  2014       NaN         NaN\n",
       "141    MRK  2014       NaN         NaN\n",
       "172    PEP  2014       NaN         NaN\n",
       "183    TMO  2014       NaN         NaN\n",
       "184    ABT  2014       NaN         NaN\n",
       "195    AMD  2014       NaN         NaN\n",
       "196     PM  2014       NaN         NaN\n",
       "197   ISRG  2014       NaN         NaN\n",
       "198   INTU  2014       NaN         NaN\n",
       "199     GS  2014       NaN         NaN\n",
       "200    TXN  2014       NaN         NaN\n",
       "211   BKNG  2014       NaN         NaN\n",
       "212    DHR  2014       NaN         NaN\n",
       "223    NEE  2014       NaN         NaN\n",
       "234   ANET  2014       NaN         NaN\n",
       "245    LOW  2014       NaN         NaN\n",
       "246    SYK  2014       NaN         NaN\n",
       "248    UNP  2015       NaN         NaN\n",
       "259    KKR  2014       NaN         NaN\n",
       "260   SCHW  2014       NaN         NaN\n",
       "261   AMAT  2014       NaN         NaN\n",
       "312    BMY  2014       NaN         NaN\n",
       "313    LMT  2014       NaN         NaN\n",
       "314   GILD  2014       NaN         NaN\n",
       "315    NKE  2014       NaN         NaN\n",
       "336    ADI  2014       NaN         NaN\n",
       "337    MMC  2014       NaN         NaN\n",
       "348     MU  2014       NaN         NaN\n",
       "349   SBUX  2014       NaN         NaN\n",
       "350    PLD  2014       NaN         NaN\n",
       "351   LRCX  2014       NaN         NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查缺值\n",
    "df = pd.read_csv(financials_file)\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [04:37<00:00,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 2014, [(182795000000.0, 'SalesRevenueNet')]]\n",
      "['MSFT', 2014, [(159781000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet')]]\n",
      "['AMZN', 2014, [(177976000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet+SalesRevenueServicesNet')]]\n",
      "['MA', 2015, [(9667000000.0, 'SalesRevenueNet')]]\n",
      "['ORCL', 2014, [(38226000000.0, 'Revenues')]]\n",
      "['PG', 2015, [(70749000000.0, 'SalesRevenueNet')]]\n",
      "['HD', 2014, [(86976000000.0, 'SalesRevenueNet+SalesRevenueServicesNet')]]\n",
      "['ABBV', 2014, [(19960000000.0, 'SalesRevenueNet')]]\n",
      "['KO', 2014, [(45998000000.0, 'SalesRevenueGoodsNet')]]\n",
      "['MRK', 2014, [(42237000000.0, 'SalesRevenueGoodsNet')]]\n",
      "['PEP', 2014, [(66683000000.0, 'SalesRevenueNet')]]\n",
      "['TMO', 2014, [(16889600000.0, 'Revenues')]]\n",
      "['ABT', 2014, [(20247000000.0, 'SalesRevenueNet')]]\n",
      "['AMD', 2014, [(11012000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet')]]\n",
      "['PM', 2014, [(80106000000.0, 'SalesRevenueNet')]]\n",
      "['ISRG', 2014, [(4263400000.0, 'SalesRevenueNet+SalesRevenueGoodsNet+SalesRevenueServicesNet')]]\n",
      "['INTU', 2014, [(8486000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet+SalesRevenueServicesNet')]]\n",
      "['GS', 2014, [(34528000000.0, 'RevenuesNetOfInterestExpense')]]\n",
      "['TXN', 2014, [(13045000000.0, 'SalesRevenueNet')]]\n",
      "['BKNG', 2014, [(8441971000.0, 'SalesRevenueNet')]]\n",
      "['DHR', 2014, [(12866900000.0, 'SalesRevenueNet')]]\n",
      "['NEE', 2014, [(17021000000.0, 'RegulatedAndUnregulatedOperatingRevenue')]]\n",
      "['ANET', 2014, [(1168212000.0, 'SalesRevenueNet+SalesRevenueGoodsNet+SalesRevenueServicesNet')]]\n",
      "['LOW', 2014, [(56223000000.0, 'SalesRevenueNet')]]\n",
      "['SYK', 2014, [(9675000000.0, 'SalesRevenueNet')]]\n",
      "['UNP', 2015, [(21813000000.0, 'Revenues')]]\n",
      "['KKR', 2014, []]\n",
      "['SCHW', 2014, [(6058000000.0, 'Revenues')]]\n",
      "['AMAT', 2014, [(9072000000.0, 'SalesRevenueNet')]]\n",
      "['BMY', 2014, [(27539000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet')]]\n",
      "['LMT', 2014, [(79892000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet+SalesRevenueServicesNet')]]\n",
      "['GILD', 2014, [(49364000000.0, 'SalesRevenueNet+SalesRevenueGoodsNet')]]\n",
      "['NKE', 2014, [(30601000000.0, 'SalesRevenueNet')]]\n",
      "['ADI', 2014, [(2864773000.0, 'SalesRevenueNet')]]\n",
      "['MMC', 2014, [(12951000000.0, 'SalesRevenueServicesNet')]]\n",
      "['MU', 2014, [(16358000000.0, 'SalesRevenueNet')]]\n",
      "['SBUX', 2014, [(16447800000.0, 'SalesRevenueNet')]]\n",
      "['PLD', 2014, [(1760787000.0, 'RealEstateRevenueNet')]]\n",
      "['LRCX', 2014, [(5259312000.0, 'SalesRevenueNet')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"financials.csv\")  # 替換成你的檔名\n",
    "missing_df = df[df.isnull().any(axis=1)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(missing_df.iterrows(), total=len(missing_df)):\n",
    "    ticker = row[\"ticker\"]\n",
    "    year = int(row[\"year\"])\n",
    "\n",
    "    results.append([ticker, year, extract_financials(ticker, year)])\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5872631000.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2014\n",
    "cik = \"KKR\"\n",
    "company = Company(cik)\n",
    "filing = company.get_filings(form=\"10-K\", date=f\"{year}-04-01:{year+1}-12-31\")[-1]\n",
    "df = company.get_facts().to_pandas()\n",
    "df = df[df[\"namespace\"] == \"us-gaap\"]\n",
    "url = f\"https://www.sec.gov/Archives/edgar/data/{filing.cik}/{filing.accession_no.replace('-', '')}/{filing.primary_document}\"\n",
    "\n",
    "result = extract_financials(cik, year)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AvailableForSaleDebtSecuritiesAccumulatedGrossUnrealizedGainBeforeTax',\n",
       " 'AvailableForSaleDebtSecuritiesAccumulatedGrossUnrealizedLossBeforeTax',\n",
       " 'AvailableForSaleDebtSecuritiesAmortizedCostBasis',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterFiveThroughTenYearsAmortizedCost',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterFiveThroughTenYearsFairValue',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterOneThroughFiveYearsAmortizedCost',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterOneThroughFiveYearsFairValue',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterTenYearsAmortizedCost',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesAfterTenYearsFairValue',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesSingleMaturityDate',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesSingleMaturityDateAmortizedCostBasis',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesWithinOneYearAmortizedCost',\n",
       " 'AvailableForSaleSecuritiesDebtMaturitiesWithinOneYearFairValue',\n",
       " 'AvailableForSaleSecuritiesDebtSecurities',\n",
       " 'DebtSecuritiesAvailableForSaleAllowanceForCreditLoss',\n",
       " 'DebtSecuritiesAvailableForSaleAllowanceForCreditLossNotPreviouslyRecorded',\n",
       " 'DebtSecuritiesAvailableForSaleAllowanceForCreditLossNotToSellBeforeRecoveryCreditLossPreviouslyRecordedExpenseReversal',\n",
       " 'DebtSecuritiesAvailableForSaleAllowanceForCreditLossPurchasedWithCreditDeteriorationIncrease',\n",
       " 'DebtSecuritiesAvailableForSaleAllowanceForCreditLossSecuritiesSold',\n",
       " 'DebtSecuritiesAvailableForSaleAmortizedCostAfterAllowanceForCreditLoss',\n",
       " 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPosition12MonthsOrLonger',\n",
       " 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPosition12MonthsOrLongerAccumulatedLoss',\n",
       " 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPositionLessThan12Months',\n",
       " 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPositionLessThan12MonthsAccumulatedLoss',\n",
       " 'DebtSecuritiesAvailableForSalePurchasedWithCreditDeteriorationAllowanceForCreditLossAtAcquisitionDate',\n",
       " 'DebtSecuritiesAvailableForSalePurchasedWithCreditDeteriorationAmountAtParValue',\n",
       " 'DebtSecuritiesAvailableForSalePurchasedWithCreditDeteriorationAmountAtPurchasePrice',\n",
       " 'DebtSecuritiesAvailableForSalePurchasedWithCreditDeteriorationDiscountPremium',\n",
       " 'DebtSecuritiesAvailableForSaleRealizedGain',\n",
       " 'DebtSecuritiesAvailableForSaleRealizedLoss',\n",
       " 'DebtSecuritiesAvailableForSaleUnrealizedLossPosition',\n",
       " 'DebtSecuritiesAvailableForSaleUnrealizedLossPositionAccumulatedLoss',\n",
       " 'DebtSecuritiesAvailableForSaleUnrealizedLossPositionNumberOfPositions',\n",
       " 'GainLossOnSaleOfOilAndGasProperty',\n",
       " 'OtherComprehensiveIncomeLossAvailableForSaleSecuritiesAdjustmentNetOfTax',\n",
       " 'ProceedsFromSaleMaturityAndCollectionsOfInvestments',\n",
       " 'ProceedsFromSaleOfAvailableForSaleSecuritiesDebt',\n",
       " 'ProceedsFromSaleOfInterestInPartnershipUnit',\n",
       " 'ProceedsFromSaleOfOilAndGasPropertyAndEquipment',\n",
       " 'ProceedsFromSaleOfSecuritiesOperatingActivities',\n",
       " 'OtherComprehensiveIncomeLossAvailableForSaleSecuritiesBeforeReclassificationAdjustmentsTax',\n",
       " 'DebtSecuritiesAvailableForSaleAmortizedCostAllowanceForCreditLossExcludingAccruedInterest',\n",
       " 'DebtSecuritiesAvailableForSaleAmortizedCostExcludingAccruedInterestAfterAllowanceForCreditLoss',\n",
       " 'DebtSecuritiesAvailableForSaleAmortizedCostExcludingAccruedInterestBeforeAllowanceForCreditLoss',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterest',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterestAllowanceForCreditLossNotPreviouslyRecorded',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterestAllowanceForCreditLossNotToSellBeforeRecoveryCreditLossPreviouslyRecordedExpenseReversal',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterestAllowanceForCreditLossSecuritiesSold',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterestPurchasedWithCreditDeteriorationAllowanceForCreditLossAtAcquisitionDate',\n",
       " 'DebtSecuritiesAvailableForSaleExcludingAccruedInterestAllowanceForCreditLossWriteoff']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in df[\"fact\"].unique() if \"Sale\" in f]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
